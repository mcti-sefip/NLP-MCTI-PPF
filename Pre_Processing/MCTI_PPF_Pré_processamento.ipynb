{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bbv39DbHq8y"
      },
      "source": [
        "# Introdução\n",
        "Este notebook é relativo a etapa de pré-processamento do projeto TED MCTI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Uz4e8HDjWXp"
      },
      "source": [
        "## Importando as Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSi7BNyUZWgW",
        "outputId": "8b72abc1-91ff-461f-c62e-1db4e8f7e096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting translators\n",
            "  Downloading translators-5.4.2-py3-none-any.whl (29 kB)\n",
            "Collecting loguru>=0.6.0\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting pathos>=0.2.9\n",
            "  Downloading pathos-0.2.9-py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting PyExecJS>=1.5.1\n",
            "  Downloading PyExecJS-1.5.1.tar.gz (13 kB)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.7/dist-packages (from translators) (4.9.1)\n",
            "Collecting requests>=2.28.1\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting ppft>=1.7.6.5\n",
            "  Downloading ppft-1.7.6.5-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 514 kB/s \n",
            "\u001b[?25hCollecting pox>=0.3.1\n",
            "  Downloading pox-0.3.1-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: dill>=0.3.5.1 in /usr/local/lib/python3.7/dist-packages (from pathos>=0.2.9->translators) (0.3.5.1)\n",
            "Collecting multiprocess>=0.70.13\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 30.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.7.3 in /usr/local/lib/python3.7/dist-packages (from ppft>=1.7.6.5->pathos>=0.2.9->translators) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28.1->translators) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28.1->translators) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28.1->translators) (2.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.28.1->translators) (1.24.3)\n",
            "Building wheels for collected packages: PyExecJS\n",
            "  Building wheel for PyExecJS (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyExecJS: filename=PyExecJS-1.5.1-py3-none-any.whl size=14598 sha256=b38ecfaecc8d78ef120ad1ec793f381c588d4c7e52764bf2b7a3447f2ef19ec1\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/ee/03/da5c0b4a8c13362beeb844eb913bbe58a89bde1de2b9157007\n",
            "Successfully built PyExecJS\n",
            "Installing collected packages: ppft, pox, multiprocess, requests, PyExecJS, pathos, loguru, translators\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed PyExecJS-1.5.1 loguru-0.6.0 multiprocess-0.70.13 pathos-0.2.9 pox-0.3.1 ppft-1.7.6.5 requests-2.28.1 translators-5.4.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.72-py2.py3-none-any.whl (8.3 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 68.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.72 pyahocorasick-1.4.4 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install translators --upgrade\n",
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW2_EBTEUiCb",
        "outputId": "0823ab50-e97a-42bd-9c0d-be56aac0a727"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using state South Carolina server backend.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "import math\n",
        "import time\n",
        "import re\n",
        "import contractions\n",
        "import unicodedata\n",
        "import translators as ts\n",
        "\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Embedding\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqvWg8-lj4Hl"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldCHUHCuZ1qD"
      },
      "source": [
        "## Funções de treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "l15_9vTtZ4zg"
      },
      "outputs": [],
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECxIO_nLaBN3"
      },
      "outputs": [],
      "source": [
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "FgamzXjtKwsW"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import io\n",
        "import shutil\n",
        "\n",
        "def write_list(a_list, file_name):\n",
        "    with open(file_name, \"w\") as fp:\n",
        "        json.dump(a_list, fp)\n",
        "\n",
        "def read_list(url):\n",
        "    myfile = requests.get(url)\n",
        "    myfile.raise_for_status()\n",
        "    n_list = json.load(io.BytesIO(myfile.content))\n",
        "    return n_list\n",
        "\n",
        "def read_labels(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    data = np.load(io.BytesIO(response.content))\n",
        "    return np.array(data)\n",
        "\n",
        "def get_model(filename, url):\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(filename, 'wb') as fin:\n",
        "        shutil.copyfileobj(response.raw, fin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Mi_KM1CPV2be"
      },
      "outputs": [],
      "source": [
        "def train_network(word_list, labels, save_as='best weights.h5'):\n",
        "  vocab = []\n",
        "  for sentence in word_list:\n",
        "    for word in sentence:\n",
        "      if word not in vocab:\n",
        "        vocab.append(word)\n",
        "\n",
        "  vocab_size = len(set(vocab))\n",
        "  input_vector = []\n",
        "  i = 0\n",
        "  for sentence in word_list:\n",
        "    input_vector.append([one_hot(word, vocab_size, filters='') for word in sentence])\n",
        "\n",
        "  max_size = 0\n",
        "  for sentence in input_vector:\n",
        "    if len(sentence) > max_size:\n",
        "      max_size = len(sentence)\n",
        "\n",
        "  input_vector = pad_sequences(input_vector, maxlen=max_size, padding='pre')\n",
        "\n",
        "  # Split dataset into train and test data\n",
        "  x_train, x_test, y_train, y_test = train_test_split(input_vector, \n",
        "                                                      labels, \n",
        "                                                      test_size=0.20, \n",
        "                                                      random_state=20)\n",
        "  \n",
        "  # Creating the Network\n",
        "  model_NN = Sequential() \n",
        "  model_NN.add(Embedding(vocab_size, 8, input_length=len(input_vector[0])))\n",
        "  model_NN.add(Flatten())\n",
        "  model_NN.add(Dense(1, activation='relu'))\n",
        "\n",
        "  # add checkpoint to save the network and stop if training doesn't improve MCTI\n",
        "  checkpoint = keras.callbacks.ModelCheckpoint(save_as, monitor='val_accuracy', verbose=1, \n",
        "                              save_best_only=True, mode='max')\n",
        "  callbacks_list = [checkpoint]\n",
        "\n",
        "  model_NN.compile(optimizer='adam', loss='binary_crossentropy', \n",
        "                        metrics=['accuracy', f1_m, precision_m, recall_m])\n",
        "\n",
        "  # Fiting  the model\n",
        "  history = model_NN.fit(x_train, y_train, epochs=100, \n",
        "                        callbacks=callbacks_list, verbose=2, \n",
        "                        validation_data=(x_test, y_test), \n",
        "                        batch_size=128)\n",
        "\n",
        "  # Evaluate the model\n",
        "  [modelloss, modelaccuracy, \n",
        "  modelf1, modelprecision, \n",
        "  modelrecall] = model_NN.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "  #plot_history(history)\n",
        "  return modelf1, (x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zVH7VCUHyeV"
      },
      "source": [
        "# Dataset\n",
        "Leitura dos dados MCTI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0UJpkx1Fgda",
        "outputId": "22098647-a03f-4d4d-efdf-b098b0ce1c77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MCTI Dataset has 928 examples with 21 columns of information\n"
          ]
        }
      ],
      "source": [
        "url= 'https://github.com/chap0lin/PPF-MCTI/blob/master/Datasets/oportunidadesrotulo%20-%20%C3%9Altima.xlsx?raw=true'\n",
        "myfile = requests.get(url)\n",
        "dataMCTI = pd.read_excel(myfile.content)\n",
        "\n",
        "print(\"MCTI Dataset has \" + str(dataMCTI.shape[0]) + \" examples with \" + str(dataMCTI.shape[1]) + \" columns of information\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "-wPIgPN8XIoS",
        "outputId": "49a95968-e75e-47e4-c702-17ddf20f8bb7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7c27f51c-a46d-4eaa-aec6-e88d0d34e15a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ordem</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>atualizacao</th>\n",
              "      <th>codigo</th>\n",
              "      <th>link</th>\n",
              "      <th>opo_deadline</th>\n",
              "      <th>opo_texto</th>\n",
              "      <th>opo_texto_ele</th>\n",
              "      <th>opo_tipo</th>\n",
              "      <th>...</th>\n",
              "      <th>opo_dificuldade</th>\n",
              "      <th>rotulagem</th>\n",
              "      <th>opo_brazil</th>\n",
              "      <th>classificado</th>\n",
              "      <th>Tamanho do Texto</th>\n",
              "      <th>Tamanho doTítulo</th>\n",
              "      <th>Quantidade de Sentenças no Texto</th>\n",
              "      <th>Média Sentença</th>\n",
              "      <th>QTD Branco</th>\n",
              "      <th>opo_texto.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>220329</td>\n",
              "      <td>dfg_220329_1_000</td>\n",
              "      <td>https://www.dfg.de/en/research_funding/announc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Deutsche Forschungsgemeinschaft (DFG, Germ...</td>\n",
              "      <td>The Deutsche Forschungsgemeinschaft (DFG, Germ...</td>\n",
              "      <td>other</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>vitor</td>\n",
              "      <td>Y</td>\n",
              "      <td>S</td>\n",
              "      <td>3487</td>\n",
              "      <td>123</td>\n",
              "      <td>34</td>\n",
              "      <td>102</td>\n",
              "      <td>455</td>\n",
              "      <td>The Deutsche Forschungsgemeinschaft (DFG, Germ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>220329</td>\n",
              "      <td>dfg_220329_1_001</td>\n",
              "      <td>https://www.dfg.de/en/research_funding/announc...</td>\n",
              "      <td>second</td>\n",
              "      <td>In March 2018, the Senate of the Deutsche Fors...</td>\n",
              "      <td>In March 2018, the Senate of the Deutsche Fors...</td>\n",
              "      <td>other</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>vitor</td>\n",
              "      <td>N</td>\n",
              "      <td>S</td>\n",
              "      <td>7280</td>\n",
              "      <td>92</td>\n",
              "      <td>67</td>\n",
              "      <td>108</td>\n",
              "      <td>945</td>\n",
              "      <td>In March 2018, the Senate of the Deutsche Fors...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>220329</td>\n",
              "      <td>dfg_220329_1_002</td>\n",
              "      <td>https://www.dfg.de/en/research_funding/announc...</td>\n",
              "      <td>JSPS-DFG 2022</td>\n",
              "      <td>JSPS-DFG 2022</td>\n",
              "      <td>JSPS-DFG 2022</td>\n",
              "      <td>other</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>vitor</td>\n",
              "      <td>N</td>\n",
              "      <td>S</td>\n",
              "      <td>13</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>JSPS-DFG 2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>220329</td>\n",
              "      <td>dfg_220329_1_003</td>\n",
              "      <td>https://www.dfg.de/en/research_funding/announc...</td>\n",
              "      <td>########</td>\n",
              "      <td>The Deutsche Forschungsgemeinschaft (DFG, Germ...</td>\n",
              "      <td>The Deutsche Forschungsgemeinschaft (DFG, Germ...</td>\n",
              "      <td>grant</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>vitor</td>\n",
              "      <td>N</td>\n",
              "      <td>S</td>\n",
              "      <td>5325</td>\n",
              "      <td>71</td>\n",
              "      <td>60</td>\n",
              "      <td>88</td>\n",
              "      <td>642</td>\n",
              "      <td>The Deutsche Forschungsgemeinschaft (DFG, Germ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>220329</td>\n",
              "      <td>dfg_220329_1_004</td>\n",
              "      <td>https://www.dfg.de/en/research_funding/announc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Within the current funding initiative on next ...</td>\n",
              "      <td>Within the current funding initiative on next ...</td>\n",
              "      <td>grant</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>vitor</td>\n",
              "      <td>N</td>\n",
              "      <td>S</td>\n",
              "      <td>7278</td>\n",
              "      <td>28</td>\n",
              "      <td>77</td>\n",
              "      <td>94</td>\n",
              "      <td>1002</td>\n",
              "      <td>Within the current funding initiative on next ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c27f51c-a46d-4eaa-aec6-e88d0d34e15a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c27f51c-a46d-4eaa-aec6-e88d0d34e15a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c27f51c-a46d-4eaa-aec6-e88d0d34e15a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Ordem  Unnamed: 0  Unnamed: 0.1  atualizacao            codigo  \\\n",
              "0      0           0             0       220329  dfg_220329_1_000   \n",
              "1      1           1             1       220329  dfg_220329_1_001   \n",
              "2      2           2             2       220329  dfg_220329_1_002   \n",
              "3      3           3             3       220329  dfg_220329_1_003   \n",
              "4      4           4             4       220329  dfg_220329_1_004   \n",
              "\n",
              "                                                link   opo_deadline  \\\n",
              "0  https://www.dfg.de/en/research_funding/announc...            NaN   \n",
              "1  https://www.dfg.de/en/research_funding/announc...         second   \n",
              "2  https://www.dfg.de/en/research_funding/announc...  JSPS-DFG 2022   \n",
              "3  https://www.dfg.de/en/research_funding/announc...       ########   \n",
              "4  https://www.dfg.de/en/research_funding/announc...            NaN   \n",
              "\n",
              "                                           opo_texto  \\\n",
              "0  The Deutsche Forschungsgemeinschaft (DFG, Germ...   \n",
              "1  In March 2018, the Senate of the Deutsche Fors...   \n",
              "2                                      JSPS-DFG 2022   \n",
              "3  The Deutsche Forschungsgemeinschaft (DFG, Germ...   \n",
              "4  Within the current funding initiative on next ...   \n",
              "\n",
              "                                       opo_texto_ele opo_tipo  ...  \\\n",
              "0  The Deutsche Forschungsgemeinschaft (DFG, Germ...    other  ...   \n",
              "1  In March 2018, the Senate of the Deutsche Fors...    other  ...   \n",
              "2                                      JSPS-DFG 2022    other  ...   \n",
              "3  The Deutsche Forschungsgemeinschaft (DFG, Germ...    grant  ...   \n",
              "4  Within the current funding initiative on next ...    grant  ...   \n",
              "\n",
              "  opo_dificuldade  rotulagem opo_brazil classificado Tamanho do Texto  \\\n",
              "0             1.0      vitor          Y            S             3487   \n",
              "1             1.0      vitor          N            S             7280   \n",
              "2             1.0      vitor          N            S               13   \n",
              "3             1.0      vitor          N            S             5325   \n",
              "4             1.0      vitor          N            S             7278   \n",
              "\n",
              "   Tamanho doTítulo  Quantidade de Sentenças no Texto  Média Sentença  \\\n",
              "0               123                                34             102   \n",
              "1                92                                67             108   \n",
              "2               127                                 0               0   \n",
              "3                71                                60              88   \n",
              "4                28                                77              94   \n",
              "\n",
              "   QTD Branco                                        opo_texto.1  \n",
              "0         455  The Deutsche Forschungsgemeinschaft (DFG, Germ...  \n",
              "1         945  In March 2018, the Senate of the Deutsche Fors...  \n",
              "2           1                                      JSPS-DFG 2022  \n",
              "3         642  The Deutsche Forschungsgemeinschaft (DFG, Germ...  \n",
              "4        1002  Within the current funding initiative on next ...  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataMCTI.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "xOOH0g3B_gHa"
      },
      "outputs": [],
      "source": [
        "labels = dataMCTI['opo_brazil']\n",
        "labelsMCTI = np.where(labels == \"Y\", 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ldYaNhcVBRe"
      },
      "source": [
        "# Base - Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldbWgESCYdZT"
      },
      "source": [
        "## Formatando opo_texto e opo_texto_ele"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQCFdIHDjYnn"
      },
      "source": [
        "A partir dos dados raspados e catalogados no projeto, pode-se perceber uma divergencia em alguns dos dados contidos na coluna opo_texto e opo_texto_ele. Para realizar o trabalho de classificação precisaramos utilizar apenas uma base de texto, e para isso foram definidas as seguintes regras:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZkVG5IHjtTu"
      },
      "source": [
        "\n",
        "\n",
        "1.   Se: `opo_texto` IGUAL `opo_texto_ele` => Utilizamos `opo_texto`\n",
        "2.   Se: `opo_texto` DIFERENTE `opo_texto_ele` E `opo_texto_ele` IGUAL \"nan\" => Utilizamos `opo_texto`\n",
        "3.   Se: `opo_texto` DIFERENTE `opo_texto_ele` E `opo_texto_ele` DIFERENTE \"nan\" E n_tokens(`opo_texto`) < 4000 => Utilizamos `opo_texto` + `opo_texto_ele`\n",
        "4.   Outros casos => Utilizamos `opo_texto`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZHHzCI3kocB"
      },
      "source": [
        "**Nota:** dos 928 dados de treino:\n",
        "\n",
        "*   795 obedecem a regra 1\n",
        "*   18 obedecem a regra 2\n",
        "*   114 obedecem a regra 3\n",
        "*   1 obedece a regra 4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6kRrRIGY08f"
      },
      "outputs": [],
      "source": [
        "opo_texto_data = dataMCTI['opo_texto']\n",
        "opo_texto_ele_data = dataMCTI['opo_texto_ele']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKpHwfRTY1Xw"
      },
      "outputs": [],
      "source": [
        "def n_tokens(text):\n",
        "  return len(nltk.word_tokenize(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZjIPpn-ZA2v"
      },
      "outputs": [],
      "source": [
        "count_regra_1 = 0\n",
        "count_regra_2 = 0\n",
        "count_regra_3 = 0\n",
        "count_regra_4 = 0\n",
        "opo_texto_final = []\n",
        "\n",
        "for i in range(len(opo_texto_data)):\n",
        "  if opo_texto_data[i] == opo_texto_ele_data[i]:\n",
        "    count_regra_1+=1\n",
        "    opo_texto_final.append(opo_texto_data[i])\n",
        "  elif pd.isna(opo_texto_ele_data[i]):\n",
        "    count_regra_2+=1\n",
        "    opo_texto_final.append(opo_texto_data[i])\n",
        "  elif n_tokens(opo_texto_data[i]) < 4000:\n",
        "    count_regra_3+=1\n",
        "    opo_texto_final.append(opo_texto_data[i]+\". \"+opo_texto_ele_data[i])\n",
        "  else:\n",
        "    count_regra_4+=1\n",
        "    opo_texto_final.append(opo_texto_data[i])\n",
        "\n",
        "print(count_regra_1)\n",
        "print(count_regra_2)\n",
        "print(count_regra_3)\n",
        "print(count_regra_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hY-ih_aZFf_"
      },
      "source": [
        "## Removendo caracteres especiais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEg_GZe3ZKJ-"
      },
      "outputs": [],
      "source": [
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFC', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5Hx06ZUrbEe",
        "outputId": "6b3d4ba2-daeb-46d7-fb5d-ff804a9ee92b"
      },
      "outputs": [],
      "source": [
        "opo_texto_sem_caracteres_especiais = []\n",
        "for opo in opo_texto_final:\n",
        "  opo_texto_sem_caracteres_especiais.append(remove_accented_chars(opo))\n",
        "\n",
        "print(opo_texto_final[1])\n",
        "print(opo_texto_sem_caracteres_especiais[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJSKicrtZO_n"
      },
      "source": [
        "## Traduzindo para Inglês"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaRu8zYdZWOb"
      },
      "outputs": [],
      "source": [
        "google_max_input_limit = 5000\n",
        "def translate_with_google(text):\n",
        "  if len(text) < google_max_input_limit:\n",
        "    return ts.google(text, to_language=\"en\")\n",
        "  else:\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    output = \"\"\n",
        "    for sentence in sentences:\n",
        "      output = output + ts.google(sentence, to_language=\"en\")\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bd2_0m-ZXBd"
      },
      "outputs": [],
      "source": [
        "opo_texto_traduzido = []\n",
        "for i, opo in enumerate(opo_texto_sem_caracteres_especiais):\n",
        "  if dataMCTI[\"opo_titulo\"][i][:4] == \"Bols\":\n",
        "    opo_texto_traduzido.append(translate_with_google(opo))\n",
        "  else:\n",
        "    opo_texto_traduzido.append(opo)\n",
        "\n",
        "print(opo_texto_sem_caracteres_especiais[450])\n",
        "print(opo_texto_traduzido[450])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-Kqfhk6atPd"
      },
      "source": [
        "## Tokenizando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiAuTwUFzQK5",
        "outputId": "09b5a452-6ce2-48a4-8224-a47b67934146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23784\n"
          ]
        }
      ],
      "source": [
        "vocab = []\n",
        "for sentence in sentencesMCTIList:\n",
        "  for word in sentence:\n",
        "    if word not in vocab:\n",
        "      vocab.append(word)\n",
        "\n",
        "vocab_size = len(set(vocab))\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_jEa6J2dnfA",
        "outputId": "3c41ccdc-0618-4ba3-a6b5-e26ea855e2e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['OPPORTUNITY', 'FOR', 'A', '(', '01', ')', 'TECHNICAL', 'TRS', 'Training', 'Vacancy', 'TRS', '(', 'TT-III', ')', 'with', 'FAPESP', 'Scholarship', 'in', 'the', 'Young', 'Researcher', 'IMMODULATION', 'PROJECT', 'OF', 'Iron', 'Homeostasis', 'and', 'regularity', 'of', 'the', 'Signification', 'of', 'Tyrosine', 'Quinase', 'TAM', 'During', 'infection', 'by', 'Mycobacterium', 'tuberculosis', ':', 'targets', 'for', 'development', 'of', 'host-targeted', 'immunopharmacological', 'therapies', ',', 'developed', 'at', 'the', 'Department', 'of', 'Bioquica', 'and', 'Immunology', ',', 'Ribeiro', 'Preto', 'Medical', 'School', 'of', 'the', 'University', 'of', 'So', 'Paulo', '(', 'FMRP-USP', ')', ',', 'under', 'the', 'coordination', 'of', 'Dr.', 'Diego', 'Lus', 'Costa', '.', 'The', 'selected', 'candidate', 'assist', 'in', 'the', 'maintenance', 'and', 'genotyping', 'of', 'transgenic', 'mice', 'colnies', ',', 'reagent', 'and', 'consumable', 'monitoring', 'and', 'monitoring', 'and', 'technician', 'support', 'for', 'laboratory', '.', '@', 'USP.br.More', 'information', 'about', 'requirements', 'and', 'benefits', 'of', 'FAPESP', 'TT-III', 'Scholarship', 'is', 'at', 'fapesp.br/3098', 'and', 'fapesp.br/3162', '.']\n"
          ]
        }
      ],
      "source": [
        "sentencesMCTIList_base = []\n",
        "for sentence in opo_texto_traduzido:\n",
        "  sentencesMCTIList_base.append(nltk.word_tokenize(sentence))\n",
        "print(sentencesMCTIList_base[450])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6COXZ86fbQ3w"
      },
      "source": [
        "## Treinando a rede"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObgJXe-fdMwS",
        "outputId": "b73b5470-d79e-4992-c8eb-03fcb7e19f48"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "best_i = 0\n",
        "best_f1_base = 0\n",
        "test_data = []\n",
        "while i < 10:\n",
        "  print(\"STARTING TRAINING #\" + str(i))\n",
        "  current_f1_base, test_data = train_network(sentencesMCTIList_base, labelsMCTI, \n",
        "                              \"best weights base-\" + str(i) + \".h5\")\n",
        "  if current_f1_base > best_f1_base:\n",
        "    best_f1_base = current_f1_base\n",
        "    best_i = i\n",
        "  i+=1\n",
        "print(\"Best base data preprocessing F1 Score: \" + str(best_f1_base))\n",
        "print(best_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4ajgz6QIBtg"
      },
      "source": [
        "# Experimentos de pré-processamento\n",
        "Condução de experimentos com o objetivo de encontrar a combinação de técnicas de pré-processamento que entreguem os melhores resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2bjwL9LFHcG"
      },
      "source": [
        "## Pontuação e Capitalização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6eoUMrRFHcH"
      },
      "source": [
        "### 1. Expandir Contrações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE22ZWiDFHcH",
        "outputId": "0c8f24c7-1a73-4404-cdb5-334f0f0aebba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPPORTUNITY FOR A (01) TECHNICAL TRS Training Vacancy TRS (TT-III) with FAPESP Scholarship in the Young Researcher IMMODULATION PROJECT OF IRON HOMEOSTY AND REGISTRATION OF THE SIGNAL TYPERSINE SIGNAL QUINASINE TAM DURING MYCOBACTERIUM TUBERCULOSIS: TREATS FOR DEVELOPMENT of host-targeted immunopharmacological therapies, developed at the Department of Bioquica and Immunology, Ribeiro Preto Medical School of the University of So Paulo (FMRP-USP), under the coordination of Dr. Diego Lus Costa. The selected candidate assist in the maintenance and genotyping of transgenic mice colnies, reagent and consumable monitoring and monitoring and technician support for laboratory. @USP.br.More information about requirements and benefits of FAPESP TT-III Scholarship is at fapesp.br/3098 and fapesp.br/3162.\n"
          ]
        }
      ],
      "source": [
        "sentencesExpanded = []\n",
        "for sentence in opo_texto_traduzido:\n",
        "  sentencesExpanded.append(contractions.fix(sentence))\n",
        "print(sentencesExpanded[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojo9ojHQFHcH",
        "outputId": "7d125005-af75-40f5-c41c-1599928b148f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['OPPORTUNITY', 'FOR', 'A', '(', '01', ')', 'TECHNICAL', 'TRS', 'Training', 'Vacancy', 'TRS', '(', 'TT-III', ')', 'with', 'FAPESP', 'Scholarship', 'in', 'the', 'Young', 'Researcher', 'IMMODULATION', 'PROJECT', 'OF', 'IRON', 'HOMEOSTY', 'AND', 'REGISTRATION', 'OF', 'THE', 'SIGNAL', 'TYPERSINE', 'SIGNAL', 'QUINASINE', 'TAM', 'DURING', 'MYCOBACTERIUM', 'TUBERCULOSIS', ':', 'TREATS', 'FOR', 'DEVELOPMENT', 'of', 'host-targeted', 'immunopharmacological', 'therapies', ',', 'developed', 'at', 'the', 'Department', 'of', 'Bioquica', 'and', 'Immunology', ',', 'Ribeiro', 'Preto', 'Medical', 'School', 'of', 'the', 'University', 'of', 'So', 'Paulo', '(', 'FMRP-USP', ')', ',', 'under', 'the', 'coordination', 'of', 'Dr.', 'Diego', 'Lus', 'Costa', '.', 'The', 'selected', 'candidate', 'assist', 'in', 'the', 'maintenance', 'and', 'genotyping', 'of', 'transgenic', 'mice', 'colnies', ',', 'reagent', 'and', 'consumable', 'monitoring', 'and', 'monitoring', 'and', 'technician', 'support', 'for', 'laboratory', '.', '@', 'USP.br.More', 'information', 'about', 'requirements', 'and', 'benefits', 'of', 'FAPESP', 'TT-III', 'Scholarship', 'is', 'at', 'fapesp.br/3098', 'and', 'fapesp.br/3162', '.']\n"
          ]
        }
      ],
      "source": [
        "sentencesMCTIList_xp1 = []\n",
        "for sentence in sentencesExpanded:\n",
        "  sentencesMCTIList_xp1.append(nltk.word_tokenize(sentence))\n",
        "print(sentencesMCTIList_xp1[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RQdh355NIsT",
        "outputId": "9936b8a4-612b-4f5e-bc93-9ed4da6f47ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23763\n",
            "5636\n"
          ]
        }
      ],
      "source": [
        "vocab = []\n",
        "maxsize_x1 = 0\n",
        "for sentence in sentencesMCTIList_xp1:\n",
        "  if len(sentence) > maxsize_x1:\n",
        "    maxsize_x1 = len(sentence)\n",
        "  for word in sentence:\n",
        "    if word not in vocab:\n",
        "      vocab.append(word)\n",
        "\n",
        "vocab_size_x1 = len(set(vocab))\n",
        "print(str(vocab_size_x1))\n",
        "print(maxsize_x1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whXxz8PtIxZl",
        "outputId": "2fa0aaf7-056a-4d08-9170-9b8ef460d134"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "best_i = 0\n",
        "best_f1_xp1 = 0\n",
        "test_data = []\n",
        "while i < 10:\n",
        "  print(\"STARTING TRAINING #\" + str(i))\n",
        "  current_f1_xp1, test_data = train_network(sentencesMCTIList_xp1, labelsMCTI, \n",
        "                              \"best weights xp1-\" + str(i) + \".h5\")\n",
        "  if current_f1_xp1 > best_f1_xp1:\n",
        "    best_f1_xp1 = current_f1_xp1\n",
        "    best_i = i\n",
        "  i+=1\n",
        "print(\"Best XP1 data preprocessing F1 Score: \" + str(best_f1_xp1))\n",
        "print(best_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAjx3E5sFHcI"
      },
      "source": [
        "### 2. Expandir Contrações + Transformar texto em minúsculo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeptQob4FHcI",
        "outputId": "ed08925e-7164-4343-f6d6-94f90998ac7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "opportunity for a (01) technical trs training vacancy trs (tt-iii) with fapesp scholarship in the young researcher immodulation project of iron homeosty and registration of the signal typersine signal quinasine tam during mycobacterium tuberculosis: treats for development of host-targeted immunopharmacological therapies, developed at the department of bioquica and immunology, ribeiro preto medical school of the university of so paulo (fmrp-usp), under the coordination of dr. diego lus costa. the selected candidate assist in the maintenance and genotyping of transgenic mice colnies, reagent and consumable monitoring and monitoring and technician support for laboratory. @usp.br.more information about requirements and benefits of fapesp tt-iii scholarship is at fapesp.br/3098 and fapesp.br/3162.\n"
          ]
        }
      ],
      "source": [
        "sentencesLowered = []\n",
        "for sentence in sentencesExpanded:\n",
        "  sentencesLowered.append(sentence.lower())\n",
        "print(sentencesLowered[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubp2jzpXFHcI",
        "outputId": "ea8c82d3-76e7-4d12-b459-76ecc47eb722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['opportunity', 'for', 'a', '(', '01', ')', 'technical', 'trs', 'training', 'vacancy', 'trs', '(', 'tt-iii', ')', 'with', 'fapesp', 'scholarship', 'in', 'the', 'young', 'researcher', 'immodulation', 'project', 'of', 'iron', 'homeosty', 'and', 'registration', 'of', 'the', 'signal', 'typersine', 'signal', 'quinasine', 'tam', 'during', 'mycobacterium', 'tuberculosis', ':', 'treats', 'for', 'development', 'of', 'host-targeted', 'immunopharmacological', 'therapies', ',', 'developed', 'at', 'the', 'department', 'of', 'bioquica', 'and', 'immunology', ',', 'ribeiro', 'preto', 'medical', 'school', 'of', 'the', 'university', 'of', 'so', 'paulo', '(', 'fmrp-usp', ')', ',', 'under', 'the', 'coordination', 'of', 'dr.', 'diego', 'lus', 'costa', '.', 'the', 'selected', 'candidate', 'assist', 'in', 'the', 'maintenance', 'and', 'genotyping', 'of', 'transgenic', 'mice', 'colnies', ',', 'reagent', 'and', 'consumable', 'monitoring', 'and', 'monitoring', 'and', 'technician', 'support', 'for', 'laboratory', '.', '@', 'usp.br.more', 'information', 'about', 'requirements', 'and', 'benefits', 'of', 'fapesp', 'tt-iii', 'scholarship', 'is', 'at', 'fapesp.br/3098', 'and', 'fapesp.br/3162', '.']\n"
          ]
        }
      ],
      "source": [
        "sentencesMCTIList_xp2 = []\n",
        "for sentence in sentencesLowered:\n",
        "  sentencesMCTIList_xp2.append(nltk.word_tokenize(sentence))\n",
        "print(sentencesMCTIList_xp2[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZRZyjGTNaYq",
        "outputId": "7174800d-3ebe-4beb-fe4b-d139d9f205d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20320\n",
            "5629\n"
          ]
        }
      ],
      "source": [
        "vocab = []\n",
        "maxsize_x2 = 0\n",
        "for sentence in sentencesMCTIList_xp2:\n",
        "  if len(sentence) > maxsize_x2:\n",
        "    maxsize_x2 = len(sentence)\n",
        "  for word in sentence:\n",
        "    if word not in vocab:\n",
        "      vocab.append(word)\n",
        "\n",
        "vocab_size_x2 = len(set(vocab))\n",
        "print(str(vocab_size_x2))\n",
        "print(maxsize_x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bncOXGVUIxn9",
        "outputId": "1eec5c2a-4e07-48bf-e1b1-e5b30731af95"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "best_i = 0\n",
        "best_f1_xp2 = 0\n",
        "test_data = []\n",
        "while i < 10:\n",
        "  print(\"STARTING TRAINING #\" + str(i))\n",
        "  current_f1_xp2, test_data = train_network(sentencesMCTIList_xp2, labelsMCTI, \n",
        "                              \"best weights xp2-\" + str(i) + \".h5\")\n",
        "  if current_f1_xp2 > best_f1_xp2:\n",
        "    best_f1_xp2 = current_f1_xp2\n",
        "    best_i = i\n",
        "  i+=1\n",
        "print(\"Best XP2 data preprocessing F1 Score: \" + str(best_f1_xp2))\n",
        "print(best_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubNo6dLGFHcI"
      },
      "source": [
        "### 3. Expandir Contrações + Remover Pontuação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgoOlsFMFHcI",
        "outputId": "563fb2cc-7429-45b2-afca-e314cc7a3af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPPORTUNITY FOR A  TECHNICAL TRS Training Vacancy TRS TTIII with FAPESP Scholarship in the Young Researcher IMMODULATION PROJECT OF IRON HOMEOSTY AND REGISTRATION OF THE SIGNAL TYPERSINE SIGNAL QUINASINE TAM DURING MYCOBACTERIUM TUBERCULOSIS TREATS FOR DEVELOPMENT of hosttargeted immunopharmacological therapies developed at the Department of Bioquica and Immunology Ribeiro Preto Medical School of the University of So Paulo FMRPUSP under the coordination of Dr Diego Lus Costa The selected candidate assist in the maintenance and genotyping of transgenic mice colnies reagent and consumable monitoring and monitoring and technician support for laboratory USPbrMore information about requirements and benefits of FAPESP TTIII Scholarship is at fapespbr and fapespbr\n"
          ]
        }
      ],
      "source": [
        "sentencesWithoutPunctuation = []\n",
        "for sentence in sentencesExpanded:\n",
        "  sentencesWithoutPunctuation.append(remove_special_characters(sentence, remove_digits=True))\n",
        "print(sentencesWithoutPunctuation[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjgUOXoFFHcJ",
        "outputId": "1fbe00ca-c831-4034-b4c9-289f244bd6c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['OPPORTUNITY', 'FOR', 'A', 'TECHNICAL', 'TRS', 'Training', 'Vacancy', 'TRS', 'TTIII', 'with', 'FAPESP', 'Scholarship', 'in', 'the', 'Young', 'Researcher', 'IMMODULATION', 'PROJECT', 'OF', 'IRON', 'HOMEOSTY', 'AND', 'REGISTRATION', 'OF', 'THE', 'SIGNAL', 'TYPERSINE', 'SIGNAL', 'QUINASINE', 'TAM', 'DURING', 'MYCOBACTERIUM', 'TUBERCULOSIS', 'TREATS', 'FOR', 'DEVELOPMENT', 'of', 'hosttargeted', 'immunopharmacological', 'therapies', 'developed', 'at', 'the', 'Department', 'of', 'Bioquica', 'and', 'Immunology', 'Ribeiro', 'Preto', 'Medical', 'School', 'of', 'the', 'University', 'of', 'So', 'Paulo', 'FMRPUSP', 'under', 'the', 'coordination', 'of', 'Dr', 'Diego', 'Lus', 'Costa', 'The', 'selected', 'candidate', 'assist', 'in', 'the', 'maintenance', 'and', 'genotyping', 'of', 'transgenic', 'mice', 'colnies', 'reagent', 'and', 'consumable', 'monitoring', 'and', 'monitoring', 'and', 'technician', 'support', 'for', 'laboratory', 'USPbrMore', 'information', 'about', 'requirements', 'and', 'benefits', 'of', 'FAPESP', 'TTIII', 'Scholarship', 'is', 'at', 'fapespbr', 'and', 'fapespbr']\n"
          ]
        }
      ],
      "source": [
        "sentencesMCTIList_xp3 = []\n",
        "for sentence in sentencesWithoutPunctuation:\n",
        "  sentencesMCTIList_xp3.append(nltk.word_tokenize(sentence))\n",
        "print(sentencesMCTIList_xp3[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF4onkcQOPx3",
        "outputId": "7f0257c1-d567-4587-9b4e-160e73000936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22116\n",
            "4950\n"
          ]
        }
      ],
      "source": [
        "vocab = []\n",
        "maxsize_x3 = 0\n",
        "for sentence in sentencesMCTIList_xp3:\n",
        "  if len(sentence) > maxsize_x3:\n",
        "    maxsize_x3 = len(sentence)\n",
        "  for word in sentence:\n",
        "    if word not in vocab:\n",
        "      vocab.append(word)\n",
        "\n",
        "vocab_size_x3 = len(set(vocab))\n",
        "print(str(vocab_size_x3))\n",
        "print(maxsize_x3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT4W40i14h3B",
        "outputId": "e252e1d6-0e92-40d9-e76c-01de7ddbaaf0"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "best_i = 0\n",
        "best_f1_xp3 = 0\n",
        "test_data = []\n",
        "while i < 10:\n",
        "  print(\"STARTING TRAINING #\" + str(i))\n",
        "  current_f1_xp3, test_data = train_network(sentencesMCTIList_xp3, labelsMCTI, \n",
        "                              \"best weights xp3-\" + str(i) + \".h5\")\n",
        "  if current_f1_xp3 > best_f1_xp3:\n",
        "    best_f1_xp3 = current_f1_xp3\n",
        "    best_i = i\n",
        "  i+=1\n",
        "print(\"Best XP3 data preprocessing F1 Score: \" + str(best_f1_xp3))\n",
        "print(best_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pru3l4QFHcJ"
      },
      "source": [
        "### 4. Expandir Contrações + Remover Pontuação + Transformar texto em minúsculo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_-4URr4FHcJ",
        "outputId": "07b893d3-a69a-4e25-869a-4ceae32c4b71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "opportunity for a  technical trs training vacancy trs ttiii with fapesp scholarship in the young researcher immodulation project of iron homeosty and registration of the signal typersine signal quinasine tam during mycobacterium tuberculosis treats for development of hosttargeted immunopharmacological therapies developed at the department of bioquica and immunology ribeiro preto medical school of the university of so paulo fmrpusp under the coordination of dr diego lus costa the selected candidate assist in the maintenance and genotyping of transgenic mice colnies reagent and consumable monitoring and monitoring and technician support for laboratory uspbrmore information about requirements and benefits of fapesp ttiii scholarship is at fapespbr and fapespbr\n"
          ]
        }
      ],
      "source": [
        "sentencesLoweredFinal = []\n",
        "for sentence in sentencesWithoutPunctuation:\n",
        "  sentencesLoweredFinal.append(sentence.lower())\n",
        "print(sentencesLoweredFinal[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8GV0x15FHcJ",
        "outputId": "fcc43015-c313-4697-ed44-240e0db0c246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['opportunity', 'for', 'a', 'technical', 'trs', 'training', 'vacancy', 'trs', 'ttiii', 'with', 'fapesp', 'scholarship', 'in', 'the', 'young', 'researcher', 'immodulation', 'project', 'of', 'iron', 'homeosty', 'and', 'registration', 'of', 'the', 'signal', 'typersine', 'signal', 'quinasine', 'tam', 'during', 'mycobacterium', 'tuberculosis', 'treats', 'for', 'development', 'of', 'hosttargeted', 'immunopharmacological', 'therapies', 'developed', 'at', 'the', 'department', 'of', 'bioquica', 'and', 'immunology', 'ribeiro', 'preto', 'medical', 'school', 'of', 'the', 'university', 'of', 'so', 'paulo', 'fmrpusp', 'under', 'the', 'coordination', 'of', 'dr', 'diego', 'lus', 'costa', 'the', 'selected', 'candidate', 'assist', 'in', 'the', 'maintenance', 'and', 'genotyping', 'of', 'transgenic', 'mice', 'colnies', 'reagent', 'and', 'consumable', 'monitoring', 'and', 'monitoring', 'and', 'technician', 'support', 'for', 'laboratory', 'uspbrmore', 'information', 'about', 'requirements', 'and', 'benefits', 'of', 'fapesp', 'ttiii', 'scholarship', 'is', 'at', 'fapespbr', 'and', 'fapespbr']\n"
          ]
        }
      ],
      "source": [
        "sentencesMCTIList_xp4 = []\n",
        "for sentence in sentencesLoweredFinal:\n",
        "  sentencesMCTIList_xp4.append(nltk.word_tokenize(sentence))\n",
        "print(sentencesMCTIList_xp4[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYlGjurPOnpT",
        "outputId": "7fee3afc-7e88-4116-8246-cc0fe4293294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18614\n",
            "4950\n"
          ]
        }
      ],
      "source": [
        "vocab = []\n",
        "maxsize_x4 = 0\n",
        "for sentence in sentencesMCTIList_xp4:\n",
        "  if len(sentence) > maxsize_x4:\n",
        "    maxsize_x4 = len(sentence)\n",
        "  for word in sentence:\n",
        "    if word not in vocab:\n",
        "      vocab.append(word)\n",
        "\n",
        "vocab_size_x4 = len(set(vocab))\n",
        "print(str(vocab_size_x4))\n",
        "print(maxsize_x4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc-i-k2xnT0d",
        "outputId": "d993019c-8a0c-41a3-9f73-3424feb9048a"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "best_i = 0\n",
        "best_f1_xp4 = 0\n",
        "test_data = []\n",
        "while i < 10:\n",
        "  print(\"STARTING TRAINING #\" + str(i))\n",
        "  current_f1_xp4, test_data = train_network(sentencesMCTIList_xp4, labelsMCTI, \n",
        "                              \"best weights xp4-\" + str(i) + \".h5\")\n",
        "  if current_f1_xp4 > best_f1_xp4:\n",
        "    best_f1_xp4 = current_f1_xp4\n",
        "    best_i = i\n",
        "  i+=1\n",
        "print(\"Best XP4 data preprocessing F1 Score: \" + str(best_f1_xp4))\n",
        "print(best_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8CvQ_UZM9wo"
      },
      "source": [
        "## Simplificação do Conteúdo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFBobV94NEN0"
      },
      "source": [
        "### 5. Xp4 + Stemização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km-r4L65nJ0G"
      },
      "outputs": [],
      "source": [
        "ps = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3ciid9bNEhe",
        "outputId": "4610ffa4-8762-4938-9c0e-e46e59e9e9ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "opportun for a technic tr train vacanc tr ttiii with fapesp scholarship in the young research immodul project of iron homeosti and registr of the signal typersin signal quinasin tam dure mycobacterium tuberculosi treat for develop of hosttarget immunopharmacolog therapi develop at the depart of bioquica and immunolog ribeiro preto medic school of the univers of so paulo fmrpusp under the coordin of dr diego lu costa the select candid assist in the mainten and genotyp of transgen mice colni reagent and consum monitor and monitor and technician support for laboratori uspbrmor inform about requir and benefit of fapesp ttiii scholarship is at fapespbr and fapespbr\n"
          ]
        }
      ],
      "source": [
        "sentencesStemmed = []\n",
        "for sentence in sentencesMCTIList_xp4:\n",
        "  sentenceList = []\n",
        "  for word in sentence:\n",
        "    sentenceList.append(ps.stem(word))\n",
        "  sentencesStemmed.append(' '.join(w for w in sentenceList))\n",
        "print(sentencesStemmed[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX0Fi-Kitnfa",
        "outputId": "c40cf9f0-67fd-4456-c5db-2f5fc2b83175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['opportun', 'for', 'a', 'technic', 'tr', 'train', 'vacanc', 'tr', 'ttiii', 'with', 'fapesp', 'scholarship', 'in', 'the', 'young', 'research', 'immodul', 'project', 'of', 'iron', 'homeosti', 'and', 'registr', 'of', 'the', 'signal', 'typersin', 'signal', 'quinasin', 'tam', 'dure', 'mycobacterium', 'tuberculosi', 'treat', 'for', 'develop', 'of', 'hosttarget', 'immunopharmacolog', 'therapi', 'develop', 'at', 'the', 'depart', 'of', 'bioquica', 'and', 'immunolog', 'ribeiro', 'preto', 'medic', 'school', 'of', 'the', 'univers', 'of', 'so', 'paulo', 'fmrpusp', 'under', 'the', 'coordin', 'of', 'dr', 'diego', 'lu', 'costa', 'the', 'select', 'candid', 'assist', 'in', 'the', 'mainten', 'and', 'genotyp', 'of', 'transgen', 'mice', 'colni', 'reagent', 'and', 'consum', 'monitor', 'and', 'monitor', 'and', 'technician', 'support', 'for', 'laboratori', 'uspbrmor', 'inform', 'about', 'requir', 'and', 'benefit', 'of', 'fapesp', 'ttiii', 'scholarship', 'is', 'at', 'fapespbr', 'and', 'fapespbr']\n"
          ]
        }
      ],
      "source": [
        "sentencesMCTIList_xp5 = []\n",
        "for sentence in sentencesStemmed:\n",
        "  sentencesMCTIList_xp5.append(nltk.word_tokenize(sentence))\n",
        "print(sentencesMCTIList_xp5[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpUT6hAsOz6I",
        "outputId": "dde3b44f-89e1-4078-a66f-23786a043c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14317\n",
            "4950\n"
          ]
        }
      ],
      "source": [
        "vocab = []\n",
        "maxsize_x5 = 0\n",
        "for sentence in sentencesMCTIList_xp5:\n",
        "  if len(sentence) > maxsize_x5:\n",
        "    maxsize_x5 = len(sentence)\n",
        "  for word in sentence:\n",
        "    if word not in vocab:\n",
        "      vocab.append(word)\n",
        "\n",
        "vocab_size_x5 = len(set(vocab))\n",
        "print(str(vocab_size_x5))\n",
        "print(maxsize_x5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hIsS-KvnUW1",
        "outputId": "09e3d388-85a4-466d-d23b-8d02b7283913"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "best_i = 0\n",
        "best_f1_xp5 = 0\n",
        "test_data = []\n",
        "while i < 10:\n",
        "  print(\"STARTING TRAINING #\" + str(i))\n",
        "  current_f1_xp5, test_data = train_network(sentencesMCTIList_xp5, labelsMCTI, \n",
        "                              \"best weights xp5-\" + str(i) + \".h5\")\n",
        "  if current_f1_xp5 > best_f1_xp5:\n",
        "    best_f1_xp5 = current_f1_xp5\n",
        "    best_i = i\n",
        "  i+=1\n",
        "print(\"Best XP5 data preprocessing F1 Score: \" + str(best_f1_xp5))\n",
        "print(best_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wm_Mr9vCNE06"
      },
      "source": [
        "### 6. Xp4 + Lematização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJgHGWJCs_U-"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def spacy_lemmatize_text(text):\n",
        "    text = nlp(text)\n",
        "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxgcG8QSNFJ4",
        "outputId": "df6897ed-560a-4761-ab9c-d8755e5e715d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "opportunity for a   technical trs training vacancy trs ttiii with fapesp scholarship in the young researcher immodulation project of iron homeosty and registration of the signal typersine signal quinasine tam during mycobacterium tuberculosis treat for development of hosttargete immunopharmacological therapy develop at the department of bioquica and immunology ribeiro preto medical school of the university of so paulo fmrpusp under the coordination of dr diego lus costa the select candidate assist in the maintenance and genotyping of transgenic mouse colnie reagent and consumable monitoring and monitoring and technician support for laboratory uspbrmore information about requirement and benefit of fapesp ttiii scholarship be at fapespbr and fapespbr\n"
          ]
        }
      ],
      "source": [
        "sentencesLemmatized = []\n",
        "for sentence in sentencesLoweredFinal:\n",
        "  sentencesLemmatized.append(spacy_lemmatize_text(sentence))\n",
        "print(sentencesLemmatized[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66i8JdaCtGW2",
        "outputId": "93ca1790-0893-443f-938d-de26461ce7df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['opportunity', 'for', 'a', 'technical', 'trs', 'training', 'vacancy', 'trs', 'ttiii', 'with', 'fapesp', 'scholarship', 'in', 'the', 'young', 'researcher', 'immodulation', 'project', 'of', 'iron', 'homeosty', 'and', 'registration', 'of', 'the', 'signal', 'typersine', 'signal', 'quinasine', 'tam', 'during', 'mycobacterium', 'tuberculosis', 'treat', 'for', 'development', 'of', 'hosttargete', 'immunopharmacological', 'therapy', 'develop', 'at', 'the', 'department', 'of', 'bioquica', 'and', 'immunology', 'ribeiro', 'preto', 'medical', 'school', 'of', 'the', 'university', 'of', 'so', 'paulo', 'fmrpusp', 'under', 'the', 'coordination', 'of', 'dr', 'diego', 'lus', 'costa', 'the', 'select', 'candidate', 'assist', 'in', 'the', 'maintenance', 'and', 'genotyping', 'of', 'transgenic', 'mouse', 'colnie', 'reagent', 'and', 'consumable', 'monitoring', 'and', 'monitoring', 'and', 'technician', 'support', 'for', 'laboratory', 'uspbrmore', 'information', 'about', 'requirement', 'and', 'benefit', 'of', 'fapesp', 'ttiii', 'scholarship', 'be', 'at', 'fapespbr', 'and', 'fapespbr']\n"
          ]
        }
      ],
      "source": [
        "sentencesMCTIList_xp6 = []\n",
        "for sentence in sentencesLemmatized:\n",
        "  sentencesMCTIList_xp6.append(nltk.word_tokenize(sentence))\n",
        "print(sentencesMCTIList_xp6[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJpbnrfbPhVU",
        "outputId": "ae5af713-1927-47c2-8c99-514ae143106e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16191\n",
            "4950\n"
          ]
        }
      ],
      "source": [
        "vocab = []\n",
        "maxsize_x6 = 0\n",
        "for sentence in sentencesMCTIList_xp6:\n",
        "  if len(sentence) > maxsize_x6:\n",
        "    maxsize_x6 = len(sentence)\n",
        "  for word in sentence:\n",
        "    if word not in vocab:\n",
        "      vocab.append(word)\n",
        "\n",
        "vocab_size_x6 = len(set(vocab))\n",
        "print(str(vocab_size_x6))\n",
        "print(maxsize_x6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBiMsyt2nUeF",
        "outputId": "dd9d06ef-317a-4a81-d2ad-4dbfd29d7680"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "best_i = 0\n",
        "best_f1_xp6 = 0\n",
        "test_data = []\n",
        "while i < 10:\n",
        "  print(\"STARTING TRAINING #\" + str(i))\n",
        "  current_f1_xp6, test_data = train_network(sentencesMCTIList_xp6, labelsMCTI, \n",
        "                              \"best weights xp6-\" + str(i) + \".h5\")\n",
        "  if current_f1_xp6 > best_f1_xp6:\n",
        "    best_f1_xp6 = current_f1_xp6\n",
        "    best_i = i\n",
        "  i+=1\n",
        "print(\"Best XP6 data preprocessing F1 Score: \" + str(best_f1_xp6))\n",
        "print(best_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seadX-YMNU0U"
      },
      "source": [
        "### 7. Xp4 + Stemização + Remoção de StopWords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEdecMxPNrXe"
      },
      "outputs": [],
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCt8LryFKA_U",
        "outputId": "25149a01-f5a9-4128-f89b-de78e17d1e83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "opportun technic tr train vacanc tr ttiii fapesp scholarship young research immodul project iron homeosti registr signal typersin signal quinasin tam dure mycobacterium tuberculosi treat develop hosttarget immunopharmacolog therapi develop depart bioquica immunolog ribeiro preto medic school univers paulo fmrpusp coordin dr diego lu costa select candid assist mainten genotyp transgen mice colni reagent consum monitor monitor technician support laboratori uspbrmor inform requir benefit fapesp ttiii scholarship fapespbr fapespbr\n"
          ]
        }
      ],
      "source": [
        "sentencesStemStopped = []\n",
        "for sentence in sentencesStemmed:\n",
        "  sentencesStemStopped.append(remove_stopwords(sentence, is_lower_case=False))\n",
        "print(sentencesStemStopped[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIi9sfqDKV_a",
        "outputId": "bc9963c8-1b20-48d4-ad26-8fee2fc334a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['opportun', 'technic', 'tr', 'train', 'vacanc', 'tr', 'ttiii', 'fapesp', 'scholarship', 'young', 'research', 'immodul', 'project', 'iron', 'homeosti', 'registr', 'signal', 'typersin', 'signal', 'quinasin', 'tam', 'dure', 'mycobacterium', 'tuberculosi', 'treat', 'develop', 'hosttarget', 'immunopharmacolog', 'therapi', 'develop', 'depart', 'bioquica', 'immunolog', 'ribeiro', 'preto', 'medic', 'school', 'univers', 'paulo', 'fmrpusp', 'coordin', 'dr', 'diego', 'lu', 'costa', 'select', 'candid', 'assist', 'mainten', 'genotyp', 'transgen', 'mice', 'colni', 'reagent', 'consum', 'monitor', 'monitor', 'technician', 'support', 'laboratori', 'uspbrmor', 'inform', 'requir', 'benefit', 'fapesp', 'ttiii', 'scholarship', 'fapespbr', 'fapespbr']\n"
          ]
        }
      ],
      "source": [
        "sentencesMCTIList_xp7 = []\n",
        "for sentence in sentencesStemStopped:\n",
        "  sentencesMCTIList_xp7.append(nltk.word_tokenize(sentence))\n",
        "print(sentencesMCTIList_xp7[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlVnL2ufQHQD",
        "outputId": "59fa5767-0bcd-4e74-ef88-49db29cc096c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14210\n",
            "2817\n"
          ]
        }
      ],
      "source": [
        "vocab = []\n",
        "maxsize_x7 = 0\n",
        "for sentence in sentencesMCTIList_xp7:\n",
        "  if len(sentence) > maxsize_x7:\n",
        "    maxsize_x7 = len(sentence)\n",
        "  for word in sentence:\n",
        "    if word not in vocab:\n",
        "      vocab.append(word)\n",
        "\n",
        "vocab_size_x7 = len(set(vocab))\n",
        "print(str(vocab_size_x7))\n",
        "print(maxsize_x7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugoz9qaynUmS",
        "outputId": "cd5d4afd-11de-4c5b-b177-a4b396eba6c1"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "best_i = 0\n",
        "best_f1_xp7 = 0\n",
        "test_data = []\n",
        "while i < 10:\n",
        "  print(\"STARTING TRAINING #\" + str(i))\n",
        "  current_f1_xp7, test_data = train_network(sentencesMCTIList_xp7, labelsMCTI, \n",
        "                              \"best weights xp7-\" + str(i) + \".h5\")\n",
        "  if current_f1_xp7 > best_f1_xp7:\n",
        "    best_f1_xp7 = current_f1_xp7\n",
        "    best_i = i\n",
        "  i+=1\n",
        "print(\"Best XP7 data preprocessing F1 Score: \" + str(best_f1_xp7))\n",
        "print(best_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8oFU--YNrt1"
      },
      "source": [
        "### 8. Xp4 + Lematização + Remoção de StopWords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CEABRuMNvyo",
        "outputId": "0bac4c15-ad91-4fb2-ade4-6ec89d435285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "opportunity technical trs training vacancy trs ttiii fapesp scholarship young researcher immodulation project iron homeosty registration signal typersine signal quinasine tam mycobacterium tuberculosis treat development hosttargete immunopharmacological therapy develop department bioquica immunology ribeiro preto medical school university paulo fmrpusp coordination dr diego lus costa select candidate assist maintenance genotyping transgenic mouse colnie reagent consumable monitoring monitoring technician support laboratory uspbrmore information requirement benefit fapesp ttiii scholarship fapespbr fapespbr\n"
          ]
        }
      ],
      "source": [
        "sentencesLemStopped = []\n",
        "for sentence in sentencesLemmatized:\n",
        "  sentencesLemStopped.append(remove_stopwords(sentence, is_lower_case=False))\n",
        "print(sentencesLemStopped[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MY2aye6Kd1S",
        "outputId": "c8df0fdd-6aaa-43bd-a7b3-c5d167766024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['opportunity', 'technical', 'trs', 'training', 'vacancy', 'trs', 'ttiii', 'fapesp', 'scholarship', 'young', 'researcher', 'immodulation', 'project', 'iron', 'homeosty', 'registration', 'signal', 'typersine', 'signal', 'quinasine', 'tam', 'mycobacterium', 'tuberculosis', 'treat', 'development', 'hosttargete', 'immunopharmacological', 'therapy', 'develop', 'department', 'bioquica', 'immunology', 'ribeiro', 'preto', 'medical', 'school', 'university', 'paulo', 'fmrpusp', 'coordination', 'dr', 'diego', 'lus', 'costa', 'select', 'candidate', 'assist', 'maintenance', 'genotyping', 'transgenic', 'mouse', 'colnie', 'reagent', 'consumable', 'monitoring', 'monitoring', 'technician', 'support', 'laboratory', 'uspbrmore', 'information', 'requirement', 'benefit', 'fapesp', 'ttiii', 'scholarship', 'fapespbr', 'fapespbr']\n"
          ]
        }
      ],
      "source": [
        "sentencesMCTIList_xp8 = []\n",
        "for sentence in sentencesLemStopped:\n",
        "  sentencesMCTIList_xp8.append(nltk.word_tokenize(sentence))\n",
        "print(sentencesMCTIList_xp8[450])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-fjIkgjRKuq",
        "outputId": "b6dba8f0-e2ee-443e-918b-488f62f84b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16078\n",
            "2726\n"
          ]
        }
      ],
      "source": [
        "vocab = []\n",
        "maxsize_x8 = 0\n",
        "for index, sentence in enumerate(sentencesMCTIList_xp8):\n",
        "  if len(sentence) > maxsize_x8:\n",
        "    maxsize_x8 = len(sentence)\n",
        "  for word in sentence:\n",
        "    if word not in vocab:\n",
        "      vocab.append(word)\n",
        "\n",
        "vocab_size_x8 = len(set(vocab))\n",
        "print(str(vocab_size_x8))\n",
        "print(maxsize_x8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnynxADMnVKJ",
        "outputId": "b8fc5cf6-5b25-46ab-fe8f-9e7fb71c62f1"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "best_i = 0\n",
        "best_f1_xp8 = 0\n",
        "test_data = []\n",
        "while i < 10:\n",
        "  print(\"STARTING TRAINING #\" + str(i))\n",
        "  current_f1_xp8, test_data = train_network(sentencesMCTIList_xp8, labelsMCTI, \n",
        "                              \"best weights xp8-\" + str(i) + \".h5\")\n",
        "  if current_f1_xp8 > best_f1_xp8:\n",
        "    best_f1_xp8 = current_f1_xp8\n",
        "    best_i = i\n",
        "  i+=1\n",
        "print(\"Best XP8 data preprocessing F1 Score: \" + str(best_f1_xp8))\n",
        "print(best_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rwr0LiqtnhPT"
      },
      "source": [
        "# Resultados e Discussões\n",
        "Apanhado geral dos resultados obtidos com os experimentos e conclusão das melhores técnicas a serem utilizadas para o nosso problema específico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g-Gg4D-bjHG"
      },
      "source": [
        "## Resumo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-mfsBpNiUmyp"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-OQ64FgUo9D",
        "outputId": "816fcaff-3974-413f-b76a-13a9f07d1613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experimento    Descrição                Acurácia (%)    F1-score    Recall    Precisão    Tempo de treino(s)    N tokens únicos    Tamanho máximo de sentença\n",
            "-------------  ---------------------  --------------  ----------  --------  ----------  --------------------  -----------------  ----------------------------\n",
            "Base           Textos originais                89.78       84.2      79.09       90.95               417.77               23788                          5636\n",
            "xp1            Expandindo contrações           88.71       81.59     71.54       97.33               414.72               23768                          5636\n",
            "xp2            xp1 + minúsculo                 90.32       85.64     77.19       97.44               368.38               20322                          5629\n",
            "xp3            xp1 - pontuação                 91.94       87.73     79.66       98.72               386.65               22121                          4950\n",
            "xp4            xp2 - pontuação                 90.86       86.61     80.85       94.25               326.83               18616                          4950\n",
            "xp5            xp4 + stemização                91.94       87.68     78.47      100                  257.96               14319                          4950\n",
            "xp6            xp4 + lematização               89.78       85.06     79.66       91.87               282.645              16194                          4950\n",
            "xp7            xp5 - stopwords                 92.47       88.46     79.66      100                  210.32               14212                          2817\n",
            "xp8            xp6 - stopwords                 92.47       88.46     79.66      100                  225.58               16081                          2726\n"
          ]
        }
      ],
      "source": [
        "resumo_dados = [\n",
        "    [\"Base\", \"Textos originais\", 89.78, 84.20, 79.09, 90.95, 417.77, 23788, 5636],\n",
        "    [\"xp1\", \"Expandindo contrações\", 88.71, 81.59, 71.54, 97.33, 414.72, 23768, 5636],\n",
        "    [\"xp2\", \"xp1 + minúsculo\", 90.32, 85.64, 77.19, 97.44, 368.38, 20322, 5629],\n",
        "    [\"xp3\", \"xp1 - pontuação\", 91.94, 87.73, 79.66, 98.72, 386.65, 22121, 4950],\n",
        "    [\"xp4\", \"xp2 - pontuação\", 90.86, 86.61, 80.85, 94.25, 326.83, 18616, 4950],\n",
        "    [\"xp5\", \"xp4 + stemização\", 91.94, 87.68, 78.47, 100.00, 257.96, 14319, 4950], \n",
        "    [\"xp6\", \"xp4 + lematização\", 89.78, 85.06, 79.66, 91.87, 282.645, 16194, 4950], \n",
        "    [\"xp7\", \"xp5 - stopwords\", 92.47, 88.46, 79.66, 100.00, 210.32, 14212, 2817], \n",
        "    [\"xp8\", \"xp6 - stopwords\", 92.47, 88.46, 79.66, 100.00, 225.58, 16081, 2726], \n",
        "]\n",
        "headers = [\"Experimento\", \"Descrição\", \"Acurácia (%)\", \"F1-score\", \"Recall\", \"Precisão\", \"Tempo de treino(s)\",\"N tokens únicos\", \"Tamanho máximo de sentença\"]\n",
        "print(tabulate(resumo_dados, headers))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXnQj66DkLFi"
      },
      "source": [
        "## XP7 vs XP8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XsQR8TbkQ7e"
      },
      "source": [
        "Os dois experimentos apresentaram ótimos resultados de acurácia, f1-score, recall e precisão. Obtiveram os menores tempos de treinamento e os menores tamanhos de sentença. Qualquer uma das técnicas pode ser escolhida para a sequencia do trabalho.\n",
        "\n",
        "Dentre as duas excelentes opções precisamos julgar qual deve ser escolhida.\n",
        "XP7: Possui menor tempo de treinamento, menor número de tokens únicos\n",
        "XP8: Possui menor tamanhos máximos\n",
        "\n",
        "O critério utilizado para a escolha foi o custo computacional necessário para treinar os modelos de representação vetorial (word-embedding, sentence-embeddings, document-embedding). O tempo de treinamento é tão próximo que não possuiu um peso tão grande para a análise.\n",
        "- Keras Embedding:\n",
        "  - Para o keras embedding o número de tokens únicos maior apenas significa um one-hot-encoding de maior vocabulario, mas isso não aumenta o tamanho da rede.\n",
        "  - Já o tamanho da maior string modifica o tamanho do input da rede necessária pra treinar e isso é transcrito também na quantidade de pesos da camada seguinte.\n",
        "- Word2Vec:\n",
        "  - No Word2Vec o número de tokens únicos maior significa um maior tempo para o pré-treino da rede. Como esse pré-treinamento só será feito uma vez, a interferência não é tão grande. Além disso o arquivo de pesos pré-treinados do Word2Vec será maior, e ele precisará ser carregado em memória para traduzir o input para a representação vetorial. Porém, ele também pode ser descarregado da memória logo após a tradução, e não deve influenciar na memória gasta em treino.\n",
        "  - Já o tamanho maior da string quase não interfere no treinamento do Word2Vec, porém no input da rede final, e na quantidade de dados carregados em memória após a representação vetorial.\n",
        "- Longformer:\n",
        "  - O longformer já utilizado já foi pré-treinado com muito mais tokens do que os do trabalho, então o número de tokens únicos é indiferente.\n",
        "  - O tamanho maior da string também interfere muito pouco, considerando que os dois valores (2817 e 2726) são abaixo dos 4096 do tamanho da rede. Porém devemos considerar que quando o notebook for aplicado para o uso do ministério possuir um modelo capaz de reduzir mais o tamanho do input pode significar menos informação sendo truncada ou desconsiderada por ser maior que o limite máximo da rede.\n",
        "\n",
        "Diante da análise descrita, o melhor modelo de pré-processamento para esta etapa do projeto é a do **experimento 8**, que possui o menor tamanho de input para o treinamento e tende a reduzir o tamanho da entrada para o uso futuro no ministério, possivelmente impedindo de que informação seja truncada por ser maior que o limite máximo da rede.\n",
        "Vale notar que o tamanho da rede, para o caso do Keras embedding ou Word2Vec, pode ser definido pelo grupo de classificação para o valor julgado mais adequado, não necessitando se ater aos valores de encontrados no pré-processamento. Essa definição do tamanho da rede precisará ser feita depois do teste dos  modelo, que utilizarão os tamanhos mínimos encontrados aqui no pré-processamento, no caso desses modelos obterem os melhores resultados. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n2P5152KXJc"
      },
      "source": [
        "## Melhor modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "qWwstdxmK8lP"
      },
      "outputs": [],
      "source": [
        "sentencesMCTIList_xp8 = read_list(\"https://github.com/chap0lin/PPF-MCTI/blob/master/Pre-processamento/xp8_list.json?raw=true\")\n",
        "sentencesMCTIList_xp8_sentences = read_list(\"https://github.com/chap0lin/PPF-MCTI/blob/master/Pre-processamento/xp8_sent.json?raw=true\")\n",
        "labels = read_labels(\"https://github.com/chap0lin/PPF-MCTI/blob/master/Pre-processamento/labels.npy?raw=true\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "jDk055A3c4oD"
      },
      "outputs": [],
      "source": [
        "vocab = []\n",
        "for sentence in sentencesMCTIList_xp8:\n",
        "  for word in sentence:\n",
        "    if word not in vocab:\n",
        "      vocab.append(word)\n",
        "\n",
        "vocab_size = len(set(vocab))\n",
        "input_vector = []\n",
        "i = 0\n",
        "for sentence in sentencesMCTIList_xp8:\n",
        "  input_vector.append([one_hot(word, vocab_size, filters='') for word in sentence])\n",
        "\n",
        "max_size = 0\n",
        "for sentence in input_vector:\n",
        "  if len(sentence) > max_size:\n",
        "    max_size = len(sentence)\n",
        "\n",
        "input_vector = pad_sequences(input_vector, maxlen=max_size, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "J1TqO2FXc8WR"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(input_vector, \n",
        "                                                      labels, \n",
        "                                                      test_size=0.20, \n",
        "                                                      random_state=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ajS_wvsbYrP5"
      },
      "outputs": [],
      "source": [
        "get_model(\"best weights xp8.h5\", \"https://github.com/chap0lin/PPF-MCTI/blob/master/Pre-processamento/Pesos/best%20weights%20xp8.h5?raw=true\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqUFEMSgH-bj",
        "outputId": "d8ce8a07-859b-4a5f-e9fb-f3b45ed75c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XP8:\n",
            "Accuracy NN: 92.473119\n",
            "f1_score NN: 88.460702\n",
            "precision NN: 100.000000\n",
            "recall NN: 79.660153\n"
          ]
        }
      ],
      "source": [
        "path = \"best weights xp8.h5\"\n",
        "\n",
        "reconstructed_model_NN = keras.models.load_model(path, \n",
        "                                                 custom_objects={'f1_m':f1_m, \n",
        "                                                                 \"precision_m\":precision_m, \n",
        "                                                                 \"recall_m\":recall_m})\n",
        "# evaluate the model\n",
        "loss, accuracy, f1_score, precision, recall = reconstructed_model_NN.evaluate(x_test, \n",
        "                                                                              y_test, \n",
        "                                                                              verbose=0)\n",
        "\n",
        "print(\"XP8:\")\n",
        "print('Accuracy NN: %f' % (accuracy*100))\n",
        "print('f1_score NN: %f' % (f1_score*100))\n",
        "print('precision NN: %f' % (precision*100))\n",
        "print('recall NN: %f' % (recall*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iMU0vY3Mr13"
      },
      "source": [
        "# Conclusão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB9-GLeuL39p"
      },
      "source": [
        "Agora que possuímos o melhor modelo de pré-procesamento, o último passo é gerar a planilha com os campos `opo_pre` e `opo_pre_tkn` contendo o texto pré-processado em formato de sentença e tokens respectivamente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "Nfr5MfszJwx0",
        "outputId": "ca57e650-fc79-4bc7-8eb0-236668c08542"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-201945e4-ff07-4c80-b471-753e4166106b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ordem</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>atualizacao</th>\n",
              "      <th>codigo</th>\n",
              "      <th>link</th>\n",
              "      <th>opo_deadline</th>\n",
              "      <th>opo_texto</th>\n",
              "      <th>opo_texto_ele</th>\n",
              "      <th>opo_tipo</th>\n",
              "      <th>...</th>\n",
              "      <th>opo_brazil</th>\n",
              "      <th>classificado</th>\n",
              "      <th>Tamanho do Texto</th>\n",
              "      <th>Tamanho doTítulo</th>\n",
              "      <th>Quantidade de Sentenças no Texto</th>\n",
              "      <th>Média Sentença</th>\n",
              "      <th>QTD Branco</th>\n",
              "      <th>opo_texto.1</th>\n",
              "      <th>opo_pre_tkn</th>\n",
              "      <th>opo_pre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>220329</td>\n",
              "      <td>dfg_220329_1_000</td>\n",
              "      <td>https://www.dfg.de/en/research_funding/announc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Deutsche Forschungsgemeinschaft (DFG, Germ...</td>\n",
              "      <td>The Deutsche Forschungsgemeinschaft (DFG, Germ...</td>\n",
              "      <td>other</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>S</td>\n",
              "      <td>3487</td>\n",
              "      <td>123</td>\n",
              "      <td>34</td>\n",
              "      <td>102</td>\n",
              "      <td>455</td>\n",
              "      <td>The Deutsche Forschungsgemeinschaft (DFG, Germ...</td>\n",
              "      <td>[deutsche, forschungsgemeinschaft, dfg, german...</td>\n",
              "      <td>deutsche forschungsgemeinschaft dfg german res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>220329</td>\n",
              "      <td>dfg_220329_1_001</td>\n",
              "      <td>https://www.dfg.de/en/research_funding/announc...</td>\n",
              "      <td>second</td>\n",
              "      <td>In March 2018, the Senate of the Deutsche Fors...</td>\n",
              "      <td>In March 2018, the Senate of the Deutsche Fors...</td>\n",
              "      <td>other</td>\n",
              "      <td>...</td>\n",
              "      <td>N</td>\n",
              "      <td>S</td>\n",
              "      <td>7280</td>\n",
              "      <td>92</td>\n",
              "      <td>67</td>\n",
              "      <td>108</td>\n",
              "      <td>945</td>\n",
              "      <td>In March 2018, the Senate of the Deutsche Fors...</td>\n",
              "      <td>[march, senate, deutsche, forschungsgemeinscha...</td>\n",
              "      <td>march senate deutsche forschungsgemeinschaft d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>220329</td>\n",
              "      <td>dfg_220329_1_002</td>\n",
              "      <td>https://www.dfg.de/en/research_funding/announc...</td>\n",
              "      <td>JSPS-DFG 2022</td>\n",
              "      <td>JSPS-DFG 2022</td>\n",
              "      <td>JSPS-DFG 2022</td>\n",
              "      <td>other</td>\n",
              "      <td>...</td>\n",
              "      <td>N</td>\n",
              "      <td>S</td>\n",
              "      <td>13</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>JSPS-DFG 2022</td>\n",
              "      <td>[jspsdfg]</td>\n",
              "      <td>jspsdfg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>220329</td>\n",
              "      <td>dfg_220329_1_003</td>\n",
              "      <td>https://www.dfg.de/en/research_funding/announc...</td>\n",
              "      <td>########</td>\n",
              "      <td>The Deutsche Forschungsgemeinschaft (DFG, Germ...</td>\n",
              "      <td>The Deutsche Forschungsgemeinschaft (DFG, Germ...</td>\n",
              "      <td>grant</td>\n",
              "      <td>...</td>\n",
              "      <td>N</td>\n",
              "      <td>S</td>\n",
              "      <td>5325</td>\n",
              "      <td>71</td>\n",
              "      <td>60</td>\n",
              "      <td>88</td>\n",
              "      <td>642</td>\n",
              "      <td>The Deutsche Forschungsgemeinschaft (DFG, Germ...</td>\n",
              "      <td>[deutsche, forschungsgemeinschaft, dfg, german...</td>\n",
              "      <td>deutsche forschungsgemeinschaft dfg german res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>220329</td>\n",
              "      <td>dfg_220329_1_004</td>\n",
              "      <td>https://www.dfg.de/en/research_funding/announc...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Within the current funding initiative on next ...</td>\n",
              "      <td>Within the current funding initiative on next ...</td>\n",
              "      <td>grant</td>\n",
              "      <td>...</td>\n",
              "      <td>N</td>\n",
              "      <td>S</td>\n",
              "      <td>7278</td>\n",
              "      <td>28</td>\n",
              "      <td>77</td>\n",
              "      <td>94</td>\n",
              "      <td>1002</td>\n",
              "      <td>Within the current funding initiative on next ...</td>\n",
              "      <td>[within, current, funding, initiative, next, g...</td>\n",
              "      <td>within current funding initiative next generat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-201945e4-ff07-4c80-b471-753e4166106b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-201945e4-ff07-4c80-b471-753e4166106b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-201945e4-ff07-4c80-b471-753e4166106b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Ordem  Unnamed: 0  Unnamed: 0.1  atualizacao            codigo  \\\n",
              "0      0           0             0       220329  dfg_220329_1_000   \n",
              "1      1           1             1       220329  dfg_220329_1_001   \n",
              "2      2           2             2       220329  dfg_220329_1_002   \n",
              "3      3           3             3       220329  dfg_220329_1_003   \n",
              "4      4           4             4       220329  dfg_220329_1_004   \n",
              "\n",
              "                                                link   opo_deadline  \\\n",
              "0  https://www.dfg.de/en/research_funding/announc...            NaN   \n",
              "1  https://www.dfg.de/en/research_funding/announc...         second   \n",
              "2  https://www.dfg.de/en/research_funding/announc...  JSPS-DFG 2022   \n",
              "3  https://www.dfg.de/en/research_funding/announc...       ########   \n",
              "4  https://www.dfg.de/en/research_funding/announc...            NaN   \n",
              "\n",
              "                                           opo_texto  \\\n",
              "0  The Deutsche Forschungsgemeinschaft (DFG, Germ...   \n",
              "1  In March 2018, the Senate of the Deutsche Fors...   \n",
              "2                                      JSPS-DFG 2022   \n",
              "3  The Deutsche Forschungsgemeinschaft (DFG, Germ...   \n",
              "4  Within the current funding initiative on next ...   \n",
              "\n",
              "                                       opo_texto_ele opo_tipo  ... opo_brazil  \\\n",
              "0  The Deutsche Forschungsgemeinschaft (DFG, Germ...    other  ...          Y   \n",
              "1  In March 2018, the Senate of the Deutsche Fors...    other  ...          N   \n",
              "2                                      JSPS-DFG 2022    other  ...          N   \n",
              "3  The Deutsche Forschungsgemeinschaft (DFG, Germ...    grant  ...          N   \n",
              "4  Within the current funding initiative on next ...    grant  ...          N   \n",
              "\n",
              "   classificado Tamanho do Texto Tamanho doTítulo  \\\n",
              "0             S             3487              123   \n",
              "1             S             7280               92   \n",
              "2             S               13              127   \n",
              "3             S             5325               71   \n",
              "4             S             7278               28   \n",
              "\n",
              "  Quantidade de Sentenças no Texto  Média Sentença  QTD Branco  \\\n",
              "0                               34             102         455   \n",
              "1                               67             108         945   \n",
              "2                                0               0           1   \n",
              "3                               60              88         642   \n",
              "4                               77              94        1002   \n",
              "\n",
              "                                         opo_texto.1  \\\n",
              "0  The Deutsche Forschungsgemeinschaft (DFG, Germ...   \n",
              "1  In March 2018, the Senate of the Deutsche Fors...   \n",
              "2                                      JSPS-DFG 2022   \n",
              "3  The Deutsche Forschungsgemeinschaft (DFG, Germ...   \n",
              "4  Within the current funding initiative on next ...   \n",
              "\n",
              "                                         opo_pre_tkn  \\\n",
              "0  [deutsche, forschungsgemeinschaft, dfg, german...   \n",
              "1  [march, senate, deutsche, forschungsgemeinscha...   \n",
              "2                                          [jspsdfg]   \n",
              "3  [deutsche, forschungsgemeinschaft, dfg, german...   \n",
              "4  [within, current, funding, initiative, next, g...   \n",
              "\n",
              "                                             opo_pre  \n",
              "0  deutsche forschungsgemeinschaft dfg german res...  \n",
              "1  march senate deutsche forschungsgemeinschaft d...  \n",
              "2                                            jspsdfg  \n",
              "3  deutsche forschungsgemeinschaft dfg german res...  \n",
              "4  within current funding initiative next generat...  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataMCTI['opo_pre_tkn'] = sentencesMCTIList_xp8\n",
        "dataMCTI['opo_pre'] = sentencesMCTIList_xp8_sentences\n",
        "dataMCTI.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "skD_PfzJLWH0"
      },
      "outputs": [],
      "source": [
        "dataMCTI.to_excel(\"oportunidades_final_pre_processado.xlsx\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0Uz4e8HDjWXp",
        "9zVH7VCUHyeV",
        "6ldYaNhcVBRe",
        "ldbWgESCYdZT",
        "-hY-ih_aZFf_",
        "VJSKicrtZO_n",
        "m-Kqfhk6atPd",
        "6COXZ86fbQ3w",
        "R4ajgz6QIBtg",
        "K6eoUMrRFHcH",
        "xAjx3E5sFHcI",
        "ubNo6dLGFHcI",
        "1pru3l4QFHcJ",
        "o8CvQ_UZM9wo",
        "NFBobV94NEN0",
        "Wm_Mr9vCNE06",
        "seadX-YMNU0U",
        "W8oFU--YNrt1",
        "6g-Gg4D-bjHG",
        "iXnQj66DkLFi"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
