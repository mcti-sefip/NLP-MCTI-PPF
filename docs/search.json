[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "O projeto NLP-MCTI-PPF é uma iniciativa do Ministério da Ciência, Tecnologia e Inovações (MCTI) em parceria com o Laboratório de Aprendizado de Máquina em Finanças e Organizações (LAMFO), no intuito de usar técnicas de processamento de linguagem natural (NLP) para analisar o portfólio de produtos financeiros de pesquisa (PPF) do Brasil para ajudar pesquisadores brasileiros a encontrar oportunidades de pesquisa dentro e fora do Brasil.\nCom o uso de técnicas de NLP, o projeto pode analisar grandes conjuntos de dados de texto, como propostas de financiamento, relatórios de pesquisa e outros documentos relacionados ao PPF, e extrair informações relevantes como palavras-chave, autores, instituições e tópicos de pesquisa. Essas informações podem então ser usadas para criar um mapa conceptual que os pesquisadores possam explorar para encontrar oportunidades de financiamento e colaboração.\nAlém disso, o projeto NLP-MCTI-PPF também pode ajudar os pesquisadores a entender melhor as tendências e lacunas na pesquisa em seu campo, identificar novas áreas de interesse e desenvolver ideias inovadoras para futuras pesquisas.\nNo contexto de ajudar os pesquisadores a encontrar oportunidades, existem várias abordagens que podem ser úteis para processar e analisar dados de texto. Dentre elas, este projeto explora algumas das abordagens listadas a abaixo, no intuito de tentar automatizar o processo de seleção para estes pesquisadores:\n\nRaspagem de dados sobre oportunidades: A raspagem de dados sobre oportunidades é uma técnica que permite coletar dados de diferentes fontes na internet, como sites de agências de financiamento, bases de dados de pesquisa e plataformas de compartilhamento de informações. Essa técnica é muito útil para reunir informações sobre oportunidades de pesquisa que podem ser difíceis de encontrar ou acessar de outras maneiras.\nPré-processamento: A primeira abordagem é o pré-processamento, que envolve a preparação dos dados de texto para análise. Isso pode incluir tarefas como limpeza de dados, remoção de ruído e formatação dos dados de maneira a torná-los mais acessíveis para análise.\nClassificação de oportunidades: A segunda abordagem é a classificação de oportunidades, que envolve a atribuição de categorias ou rótulos a oportunidades de pesquisa com base em informações presentes nos dados de texto. Isso pode ajudar os pesquisadores a organizar as oportunidades que favorecem o pesquisador, incluindo atribuir de acordo com tópicos de interesse e a encontrar oportunidades que se encaixam em suas áreas de pesquisa.\nRecomendação de oportunidades: A terceira abordagem é a Recomendação de oportunidades, que envolve o uso de algoritmos de aprendizado de máquina para sugerir oportunidades de pesquisa aos pesquisadores com base em seus interesses e histórico de pesquisa. Isso pode ajudar os pesquisadores a encontrar novas oportunidades que podem ser relevantes para suas pesquisas.\nGeração de resumo sobre as oportunidades: A quarta abordagem é a geração de resumo sobre as oportunidades, que envolve a criação de resumos curtos e concisos das oportunidades de pesquisa para facilitar a compreensão e a avaliação dessas oportunidades pelos pesquisadores. Isso pode ajudar os pesquisadores a identificar rapidamente as oportunidades que são mais relevantes para suas pesquisas e a economizar tempo na leitura de documentos detalhados.\n\nEste projeto proporciona várias linhas de pesquisa no intuito de ajudar pesquisadores brasileiros a encontrar oportunidades de pesquisa. Dentre as ferramentas utilizadas, o código está publicamente aberto no github e utiliza-se de ferramentas como gradio e plataformas como hugging-face para disponibilizar versões demos de algum dos resultados desta pesquisa.\n\n\n\n\nA raspagem de dados [link] sobre oportunidades envolve a utilização de scripts ou programas para “raspar” informações de sites da web e salvar esses dados em um formato acessível, como um arquivo de dados ou uma base de dados. Isso permitiu aos pesquisadores do projeto coletar grandes quantidades de dados de forma automatizada e rápida, economizando tempo e esforço.\nAlém disso, a raspagem de dados sobre oportunidades também pode ser combinada com técnicas de processamento de linguagem natural (NLP) para analisar os dados coletados e extrair informações relevantes, como palavras-chave, autores, instituições e tópicos de pesquisa.\n\n\n\n\nA classificação de oportunidades pode ser realizada de várias maneiras, como o uso de algoritmos de aprendizado de máquina para analisar os dados de texto e atribuir rótulos automaticamente, ou o uso de técnicas de processamento de linguagem natural (NLP) para extrair informações relevantes dos dados de texto e classificá-las manualmente.\nA classificação de oportunidades pode ser aplicada a vários tipos de dados, como propostas de financiamento, relatórios de pesquisa e outros documentos relacionados a oportunidades de pesquisa. Além disso, a classificação de oportunidades também pode ser combinada com outras técnicas de análise de dados, como a raspagem de dados e a recomendação de oportunidades, para fornecer uma visão mais ampla das oportunidades disponíveis e ajudar os pesquisadores a encontrar oportunidades relevantes para suas pesquisas.\nExistem várias tentativas de usar modelos de machine learning para realizar a classificação de oportunidades de pesquisa. Esses modelos são treinados com grandes conjuntos de dados de texto etiquetados manualmente, como propostas de financiamento, relatórios de pesquisa e outros documentos relacionados a oportunidades de pesquisa.\nNeste projeto, foi testado várias metodologias e arquiteturas de modelos diferentes descritas em [link], dentre elas o uma das aplicações utilizando o gradio está abaixo\n\n\n\n\n\nA síntese de texto é o processo de criação de resumos curtos e concisos de um texto mais longo. Isso pode ser útil para ajudar os pesquisadores a entender rapidamente o conteúdo de um documento de pesquisa ou para criar resumos de oportunidades de pesquisa que possam ser facilmente compreendidos e avaliados pelos pesquisadores.\nExistem várias tentativas de usar modelos de machine learning para realizar a síntese de texto. Um exemplo é o uso de modelos de seqüência-para-seqüência, que são treinados para gerar resumos a partir de um texto de entrada. Esses modelos são treinados com grandes conjuntos de dados de texto etiquetados manualmente, como artigos científicos e relatórios de pesquisa, e são capazes de aprender a gerar resumos que capturam a essência do texto de entrada.\nOutra técnica comum é o uso de modelos de aprendizado não supervisionado, como agrupamento de dados ou modelos de tópico, para criar resumos a partir de um texto de entrada. Esses modelos podem ajudar a identificar padrões nos dados de texto e a selecionar os trechos mais relevantes do texto para incluir no resumo.\nDentre os modelos pesquisados neste projeto, algum deles podem ser utilizados no app a seguir, no qual a descrição sobre estes pode ser encontrada em [link]\n\n\n\n\n\nA recomendação de oportunidades é o processo de sugerir oportunidades de pesquisa aos pesquisadores com base em seus interesses e histórico de pesquisa. Isso pode ser útil para ajudar os pesquisadores a encontrar novas oportunidades que possam ser relevantes para suas pesquisas e para aumentar a eficiência do processo de busca de oportunidades.\nÉ possível utilizar modelos de aprendizado de máquina para realizar a recomendação de oportunidades de maneira mais automatizada. Por exemplo, modelos de agrupamento de dados ou modelos de tópico podem ser utilizados para agrupar oportunidades de acordo com tópicos similares e sugerir oportunidades aos pesquisadores com base em seus interesses e histórico de pesquisa.\nAbaixo temos uma demostração sobre a pesquisa de recomendação disponibilizada no hugging-face, no qual a descrição do modelo pode ser encontrada no model card [link].\n\n\n\n\n\n\n\nUma revisão sistemática da literatura é um método de pesquisa que visa identificar, selecionar e avaliar de maneira sistemática todos os estudos relevantes sobre um tópico específico. O objetivo de uma revisão sistemática é fornecer uma visão geral da evidência disponível sobre um tópico e fornecer conclusões baseadas em uma análise sistemática e rigorosa dos estudos existentes.\nNeste projeto, a revisão sistemática da literatura foi aplicada em algumas das linhas de pesquisa, dentre elas: classificação de oportunidades, recomendação de oportunidades e síntese de texto sobre oportunidades.\nA revisão sistemática da literatura foi importante para iniciar o projeto de pesquisa por vários motivos:\n\nFornece uma visão geral da evidência disponível sobre o tópico de pesquisa: Ao realizar uma revisão sistemática da literatura, é possível obter uma visão geral dos estudos existentes sobre o tópico de pesquisa e compreender os principais avanços e descobertas na área. Isso pode ajudar a definir o contexto do projeto de pesquisa e a identificar lacunas na literatura que o projeto de pesquisa pode preencher.\nA revisão sistemática da literatura permite identificar as principais fontes de dados e métodos de pesquisa utilizados nos estudos existentes sobre o tópico de pesquisa. Isso pode ser útil para definir a abordagem de pesquisa e os métodos que serão utilizados no projeto de pesquisa.\nAjuda a evitar a replicação ou aperfeiçoamento de pesquisas já realizadas.\nFornece um ponto de partida para a elaboração de hipóteses e questionamentos de pesquisa permitindo identificar o que pode ser útil para definir as hipóteses e os questionamentos de pesquisa do projeto.\n\nEm resumo, a revisão sistemática da literatura é uma etapa importante na elaboração de um projeto de pesquisa, pois ajuda a definir o contexto do projeto, identificar fontes de dados e métodos de pesquisa, evitar a replicação de pesquisas já realizadas e atender aos requisitos de agências de fomento e outras instituições.\nNeste projeto, foi realizado uma linha de pesquisa com o objetivo de disponibilizar uma ferramenta de pesquisa de artigos científicos baseada no semantic scholhar [link] e um modelo para classificação artigos relevantes para a área de pesquisa proposta pelos pesquisadores deste projeto. Esta tem como intuito ajudar a retornar artigos relevantes para cada linha de pesquisa proposta do projeto de forma a reduzir o tempo necessário para efetuar a revisão sistemática da literatura completa. Esta ferramenta esta disponibilizada em [link] e o modelo se baseia em um estudo publicado na coferencia WEBIST 2022 [link] no qual ganhou título de melhor paper na 18 edição."
  }
]